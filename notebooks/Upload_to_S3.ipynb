{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a0b6963-984f-4c73-b135-b4716428aae1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.34.149)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from boto3) (0.10.2)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.149 in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from boto3) (1.34.149)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from botocore<1.35.0,>=1.34.149->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from botocore<1.35.0,>=1.34.149->boto3) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.149->boto3) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\alibo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alibo\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.1.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\alibo\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%run ./setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e283dff-df0a-40c0-b8e6-80603de53035",
   "metadata": {},
   "source": [
    " This code :\n",
    "* Reads a large CSV file (data.csv)\n",
    "* Cleans and processes the data to remove any null values.\n",
    "* Saves the data to an AWS S3 bucket (cleaned_data.csv).\n",
    "* AWS Secrets are stored in the notebook above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505ca48-c276-42e0-885b-901c974b9c46",
   "metadata": {},
   "source": [
    "The aforementioned input file in spite of its size is assumed to still fit into my laptop memory. It can be processed using pandas to cleanse and remove nulls as well as duplicatess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c04073-1311-46af-9d75-fe454dffbe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "BUCKET='mys3bucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63db811e-8eee-4f4f-9f11-10c2d117e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
    "def process_file(input_file,output_file,bucket,object_name):\n",
    "    try:\n",
    "        #1.loading CSV file into pandas dataframe\n",
    "        df=pd.read_csv(input_file)\n",
    "        #2. clean data (remove duplicates and null values)\n",
    "        df.dropna(how='any',axis=0, inplace=True)\n",
    "        df.dropna(axis=1,how='all',inplace=True)\n",
    "        print(datetime.now().strftime(\"[%Y-%m-%d][%H:%M:%S:%f] \"+\"Input file cleansed\"))\n",
    "        #3. writing pandas dataframe into a file \n",
    "        df.to_csv(output_file)\n",
    "        print(datetime.now().strftime(\"[%Y-%m-%d][%H:%M:%S:%f] \"+\"Output file created successfully!\"))\n",
    "        #4. Upload the file to s3\n",
    "        session = session = boto3.Session(\n",
    "            aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "            aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    "        )\n",
    "        print(datetime.now().strftime(\"[%Y-%m-%d][%H:%M:%S:%f] \"+\"Authenticating access to S3...\"))\n",
    "        s3 = session.resource('s3')\n",
    "        print(datetime.now().strftime(\"[%Y-%m-%d][%H:%M:%S:%f] \"+\"Uploading file into S3...\"))\n",
    "        response = s3.Bucket(BUCKET).upload_file(output_file, object_name)\n",
    "    except Exception as e:\n",
    "        print(datetime.now().strftime(\"[%Y-%m-%d][%H:%M:%S:%f] \"+str(e)))\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552c356-842b-401e-b2f1-cede98ddee5a",
   "metadata": {},
   "source": [
    "Below is a sample code to call the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff302358-4126-4528-84c5-d9ae3579d0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-30][10:16:29:074792] Input file cleansed\n",
      "[2024-07-30][10:16:29:077753] Output file created successfully!\n",
      "[2024-07-30][10:16:29:090059] Authenticating access to S3...\n",
      "[2024-07-30][10:16:29:457280] Uploading file into S3...\n",
      "[2024-07-30][10:16:30:383002] File uploaded to S3 Successfuly!\n"
     ]
    }
   ],
   "source": [
    "input_file='data.csv'\n",
    "output_file='cleansed_data.csv'\n",
    "bucket=BUCKET\n",
    "success=process_file(input_file,output_file,bucket, output_file)\n",
    "if(success==True):\n",
    "    print(datetime.now().strftime(\"[%Y-%m-%d][%H:%M:%S:%f] \"+\"File uploaded to S3 Successfuly!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6073d2-4750-4ee2-aca4-f4843c107ff4",
   "metadata": {},
   "source": [
    "For processing larger data sets particularly when it comes to data volume rather than number of records, parallel processing frameworks such as spark is recommended. Spark loads big data set into memory, distributes it across a set of worker nodes and each worker node partitions the data to process. Number of worker nodes or executors can be configured and increased or decreased based on workload and available resources to enhance scalabiity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a32cdb-9d5e-4795-82c5-ca9bff197eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
